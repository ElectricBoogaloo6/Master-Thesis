{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Konstantin\\anaconda3\\envs\\old_panda_gym_env\\lib\\site-packages\\gym\\envs\\registration.py:307: DeprecationWarning: The package name gym_robotics has been deprecated in favor of gymnasium_robotics. Please uninstall gym_robotics and install gymnasium_robotics with `pip install gymnasium_robotics`. Future releases will be maintained under the new package name gymnasium_robotics.\n",
      "  fn()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cpu\n",
      "PyTorch CUDA version: None\n",
      "CUDA available: False\n",
      "CUDA device count: 0\n",
      "CUDA device name: No GPU found\n",
      "CURRENT_DIR: c:\\Users\\Konstantin\\Documents\\Meta-learning-thesis\\active_panda\\algs\n",
      "PARENT_DIR: c:\\Users\\Konstantin\\Documents\\Meta-learning-thesis\\active_panda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "from gym import Wrapper\n",
    "import panda_gym\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "from phase_1_awac_agent import AWACAgent\n",
    "from utils_awac import ActionNormalizer, ResetWrapper, TimeFeatureWrapper, TimeLimitWrapper, RealRobotWrapper, save_results, reconstruct_state\n",
    "from phase_1_func import CustomResetWrapper, choose_task, get_participant_configuration, initialize_envs_for_condition, get_base_env\n",
    "from task_envs import Phase1TaskCentreEnv, Phase1TaskLeftEnv, Phase1TaskRightEnv\n",
    "import imageio\n",
    "\n",
    "\n",
    "CURRENT_DIR = os.getcwd() \n",
    "PARENT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "print(f\"CURRENT_DIR: {CURRENT_DIR}\")\n",
    "print(f\"PARENT_DIR: {PARENT_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demo_data(task_name, parent_dir):\n",
    "    joystick_demo_path = os.path.join(parent_dir, 'demo_data', 'joystick_demo', task_name)\n",
    "    print(f\"Looking for files in: {joystick_demo_path}\")\n",
    "    state_trajs = np.genfromtxt(os.path.join(joystick_demo_path, 'demo_state_trajs.csv'), delimiter=' ')\n",
    "    action_trajs = np.genfromtxt(os.path.join(joystick_demo_path, 'demo_action_trajs.csv'), delimiter=' ')\n",
    "    return state_trajs, action_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_demo(task_name, env, parent_dir):\n",
    "    # Load pre-existing demo data\n",
    "    state_trajs, action_trajs = load_demo_data(task_name, parent_dir)\n",
    "\n",
    "\n",
    "    # Indices where the demonstrations start\n",
    "    starting_ids = [i for i in range(state_trajs.shape[0]) if np.isinf(state_trajs[i][0])]\n",
    "    base_env = get_base_env(env)\n",
    "    base_env.enable_line_drawing = False\n",
    "\n",
    "\n",
    "    # Video parameters\n",
    "    fps = 30\n",
    "    frame_height = 720\n",
    "    frame_width  = 640\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    input(\"Press Enter to continue: \")\n",
    "\n",
    "    for i in range(len(starting_ids)):\n",
    "        starting_id = starting_ids[i]\n",
    "        if i < len(starting_ids) - 1:\n",
    "            end_id = starting_ids[i + 1]\n",
    "        else:\n",
    "            end_id = state_trajs.shape[0]\n",
    "\n",
    "        # Get initial state and actions for the current demonstration\n",
    "        init_state = state_trajs[starting_id + 1]\n",
    "        actions = action_trajs[starting_id + 1:end_id]\n",
    "\n",
    "        goal_pos = env.task.goal_position\n",
    "        object_pos = init_state[6:9]\n",
    "        \n",
    "        # Set the initial state in the environment\n",
    "        state = env.reset(goal_pos=goal_pos, object_pos=object_pos, object_color=env.object_color)\n",
    "\n",
    "        # video_filename = f\"{task_name}_demo_{i}.mp4\"\n",
    "        # out = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        curr_state_traj = []\n",
    "        curr_action_traj = []\n",
    "        curr_next_state_traj = []\n",
    "        curr_reward_traj = []\n",
    "        curr_done_traj = []\n",
    "\n",
    "        # raw_frame = env.render(mode='rgb_array')  # Possibly a 1D array/tuple\n",
    "        # frame_array = np.array(raw_frame, dtype=np.uint8)  # shape = (1382400,)\n",
    "        # # frame_reshaped = frame_array.reshape((720, 640, 3))  # or (720, 640, 3)\n",
    "        # frame_reshaped = frame_array.reshape((480, 960, 3))\n",
    "        # frame_reshaped = cv2.cvtColor(frame_reshaped, cv2.COLOR_RGB2BGR)\n",
    "        # print(\"Reshaped frame shape:\", frame_reshaped.shape)\n",
    "        # # left_half = frame_reshaped[:, :320, :]\n",
    "        # # right_half = frame_reshaped[:, 320:, :]\n",
    "        # plt.imshow(frame_reshaped)\n",
    "        # plt.show()\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.imshow(left_half)\n",
    "        # plt.title(\"Left half\")\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.imshow(right_half)\n",
    "        # plt.title(\"Right half\")\n",
    "\n",
    "        for action in actions:\n",
    "            time.sleep(0.02)\n",
    "            action_copy = action.copy()\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            reshaped_state = reconstruct_state(state)\n",
    "            reshaped_next_state = reconstruct_state(next_state)\n",
    "            \n",
    "            curr_state_traj.append(reshaped_state.copy())\n",
    "            curr_action_traj.append(action_copy)\n",
    "            curr_next_state_traj.append(reshaped_next_state.copy())\n",
    "            curr_reward_traj.append(np.array([reward]))\n",
    "            curr_done_traj.append(np.array([float(done)]))\n",
    "\n",
    "        #     raw_frame = env.render(mode='rgb_array') # a 1D array/tuple shape = (1382400,)\n",
    "\n",
    "        #     # frame = np.array(raw_frame, dtype=np.uint8)\n",
    "        #     frame = np.array(raw_frame, dtype=np.uint8).reshape((frame_height, frame_width, 3))\n",
    "        #     # If colors are reversed (e.g., BGR vs RGB), you may need to convert:\n",
    "        #     # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        #     out.write(frame)\n",
    "\n",
    "\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                env.clear_lines_gripper()\n",
    "                env.clear_lines()\n",
    "                break\n",
    "    \n",
    "        # out.release()\n",
    "        # print(f\"Saved demonstration {i} as {video_filename}\")     \n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a task type (1=left, 2=centre, 3=right):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Konstantin\\anaconda3\\envs\\old_panda_gym_env\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client id is: 0\n",
      "no default max steps\n",
      "Environment initialized successfully.\n",
      "Looking for files in: c:\\Users\\Konstantin\\Documents\\Meta-learning-thesis\\active_panda\\demo_data\\joystick_demo\\Phase1TaskLeft\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialization (as you already have it)\n",
    "    log_data = []\n",
    "    TESTING = False\n",
    "    TRAINING = True\n",
    "    TIMESTAMP = \"{0:%Y-%m-%dT%H-%M-%S/}\".format(datetime.now())\n",
    "\n",
    "    participant_code = \"train\"\n",
    "    task_type = choose_task()\n",
    "\n",
    "    if task_type == 1:\n",
    "        env = Phase1TaskLeftEnv(render=True, reward_type=\"modified_sparse\", control_type='ee')\n",
    "        task_name = \"Phase1TaskLeft\"\n",
    "    elif task_type == 2:\n",
    "        env = Phase1TaskCentreEnv(render=True, reward_type=\"modified_sparse\", control_type='ee')\n",
    "        task_name = \"Phase1TaskCentre\"\n",
    "    elif task_type == 3:\n",
    "        env = Phase1TaskRightEnv(render=True, reward_type=\"modified_sparse\", control_type='ee')\n",
    "        task_name = \"Phase1TaskRight\"\n",
    "\n",
    "    env = ActionNormalizer(env)\n",
    "    env = CustomResetWrapper(env=env)\n",
    "    env = TimeFeatureWrapper(env=env, max_steps=120, test_mode=False)\n",
    "    env = TimeLimitWrapper(env=env, max_steps=120)\n",
    "    \n",
    "    # The environment is initialized here\n",
    "    print(\"Environment initialized successfully.\")\n",
    "\n",
    "    # Pass the initialized environment (env) to rollout_demo\n",
    "    rollout_demo(task_name, env, PARENT_DIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old_panda_gym_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
